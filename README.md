# ðŸ§  PredicciÃ³n de Fallos en Sensores (Mantenimiento Predictivo)

Proyecto de Machine Learning orientado a detectar y predecir fallos en equipos industriales a partir de lecturas de sensores.  
El objetivo es anticipar incidencias y reducir paradas no planificadas, mejorando la eficiencia mediante mantenimiento predictivo.

**Tipo de problema:** ClasificaciÃ³n binaria  
**Variable objetivo:** `fail` (1 = fallo, 0 = no fallo)

---

## ðŸ§­ Objetivo y contexto

Este proyecto busca desarrollar un modelo capaz de identificar con antelaciÃ³n cuÃ¡ndo un sensor o componente puede fallar.  
En entornos industriales, detectar a tiempo un fallo potencial evita pÃ©rdidas, reduce costes de mantenimiento y permite programar intervenciones preventivas.  
Por ello, se priorizan mÃ©tricas de **recall** (minimizar falsos negativos) y **F1-score**, equilibrando precisiÃ³n y sensibilidad.

---

## ðŸ“Š Datos y variables

El dataset contiene lecturas de distintos sensores junto con una variable de salida (`fail`) que indica si hubo o no fallo.  
Las principales variables son:

- **Sensores numÃ©ricos:** `footfall`, `AQ`, `USS`, `CS`, `VOC`, `RP`, `IP`, `Temperature`  
- **CategÃ³rica:** `tempMode`  
- **Variable objetivo:** `fail` (0 = no fallo, 1 = fallo)

Los datos se cargan desde Google Drive en el notebook de Colab.  
Cada usuario debe ajustar su ruta de acceso si desea replicar el proyecto.

---

## ðŸ” AnÃ¡lisis Exploratorio (EDA)

- **Balance de clases:** relativamente equilibrado (~58% sin fallo / 42% con fallo), por lo que no se aplicaron tÃ©cnicas de re-muestreo.  
- **Valores nulos:** inexistentes; **duplicados:** se eliminÃ³ 1 registro.  
- **Outliers:** detectados principalmente en `footfall` (16%), `CS` (9%) y `Temperature` (5%). Se conservaron al considerarse valores plausibles del proceso fÃ­sico.  
- **Correlaciones:** `VOC` mostrÃ³ la relaciÃ³n mÃ¡s fuerte con `fail` (~0.8), seguida de `AQ` (~0.58) y `Temperature` (~0.19). No se observaron correlaciones entre predictores superiores a 0.9.  
- **Umbrales crÃ­ticos identificados:**  
  - `VOC â‰¥ 6`: asociado a la mayorÃ­a de los fallos (~95%)  
  - `AQ > 5`: incrementa el riesgo de fallo  
  - `footfall < 40`: tendencia a fallo  
  - `USS` en valores 1â€“2: indicativo de anomalÃ­a  

**ConclusiÃ³n:** `VOC` y `AQ` son las variables mÃ¡s influyentes.  
`footfall` mostrÃ³ una distribuciÃ³n muy asimÃ©trica, con valores extremos y dispersiÃ³n significativa, por lo que se aplicÃ³ una transformaciÃ³n logarÃ­tmica (`log1p`) para estabilizar su escala y mejorar la capacidad predictiva del modelo.

---

## âš™ï¸ Preprocesamiento

Se definiÃ³ un flujo de transformaciÃ³n robusto para garantizar coherencia entre entrenamiento y test:

1. **DivisiÃ³n estratificada 80/20:** se asegura que las proporciones de las clases `fail=0` y `fail=1` sean similares en ambos conjuntos, evitando sesgos en la evaluaciÃ³n.  
2. **SelecciÃ³n de variables:** se eliminaron las no informativas, como `tempMode`, que no presentaba relaciÃ³n con el estado de fallo.  
3. **IngenierÃ­a de caracterÃ­sticas:**  
   - TransformaciÃ³n logarÃ­tmica en `footfall`.  
   - CreaciÃ³n de banderas binarias (`flag_voc_ge6`, `flag_aq_gt5`, `flag_foot_lt40`, `flag_uss_le2`) para capturar los patrones detectados en el EDA.  
4. **Escalado y codificaciÃ³n:**  
   - `RobustScaler` en variables numÃ©ricas para mitigar el efecto de outliers.  
   - `OneHotEncoder` preparado para categÃ³ricas si se incorporan en futuras versiones.  
5. **Pipeline completo:** se integrÃ³ todo el preprocesamiento dentro de un `Pipeline` de scikit-learn, evitando fugas de informaciÃ³n (data leakage).

---

## ðŸ¤– Modelado y comparaciÃ³n

Se evaluaron cinco algoritmos de clasificaciÃ³n con validaciÃ³n cruzada estratificada (K=5):  
RegresiÃ³n LogÃ­stica, SVM, Random Forest, Gradient Boosting y Decision Tree.  
Las mÃ©tricas consideradas fueron: accuracy, precision, recall, F1 y ROC AUC.

**Resultados promedio (CV):**
- **Logistic Regression (scaled):** F1 â‰ˆ 0.887  
- **SVM (RBF, scaled):** F1 â‰ˆ 0.884  
- Los modelos basados en Ã¡rboles mostraron menor equilibrio entre recall y precisiÃ³n.

Se seleccionaron **RegresiÃ³n LogÃ­stica** y **SVM** como modelos candidatos para optimizaciÃ³n.

---

## ðŸŽ¯ OptimizaciÃ³n de hiperparÃ¡metros

Se aplicÃ³ `GridSearchCV` optimizando la mÃ©trica **F1**.  
Los mejores resultados fueron:

- **SVM (RBF):** `C=1`, `gamma='auto'`, F1 â‰ˆ 0.890  
- **Logistic Regression:** `C=1`, `penalty='l2'`, `solver='lbfgs'`, F1 â‰ˆ 0.887  

El modelo final elegido fue **SVM (RBF)** por ofrecer el mejor equilibrio entre recall y precisiÃ³n.

---

## ðŸ§ª EvaluaciÃ³n final en test

**SVM (RBF) optimizado â€“ conjunto de test:**
- Accuracy: 0.9418  
- Precision: 0.9250  
- Recall: 0.9367  
- F1-score: 0.9308  
- ROC AUC: 0.9770  

El modelo logra detectar la mayorÃ­a de los fallos (recall alto) manteniendo pocas falsas alarmas.  
Los resultados son consistentes con la validaciÃ³n cruzada, sin evidencia de sobreajuste.

---

## ðŸ’¾ Guardado del modelo

El pipeline final (preprocesamiento + modelo SVM) se guardÃ³ como archivo `.pkl` para permitir su reutilizaciÃ³n sin reentrenar.  
Cada usuario puede ajustar la ruta de guardado segÃºn su entorno.

---

## ðŸ“ Estructura del repositorio

sensor-failure-ml-project/
â”œâ”€ data/ # DocumentaciÃ³n de los datos y muestra
â”œâ”€ docs/
â”‚ â””â”€ figures/ # ImÃ¡genes y visualizaciones
â”œâ”€ models/ # Modelos entrenados (.pkl)
â”œâ”€ notebooks/ # Notebook principal del proyecto
â”œâ”€ src/ # CÃ³digo modular (funciones y scripts)
â”œâ”€ .gitignore
â”œâ”€ LICENSE
â””â”€ README.md

---

## âœï¸ Autor

**Alejandro Ãlvarez Selva**  
Proyecto de Mantenimiento Predictivo mediante Machine Learning
